---
description: >-
  The SDK allows your to programatically create and interact with Grid Runs from python.
---

# SDK Docs

The SDK all

## Top Level API Functions

API methods can be imported like: `from grid import foo`

Note: Every interpreter session needs to call the `login()` method before any utilities can
successfully proceed. 

    def login(
        username: Optional[str] = None,
        user_id: Optional[str] = None,
        api_key: Optional[str] = None,
    ):
        """Log in with your grid.ai credentials for usage of the SDK in the running process.

        All parameters are optional. Calling ``login()`` without parameters will check if
        the ``GRID_USER_ID`` and ``GRID_API_KEY`` env vars have been set (using those if
        available), otherwise it will check for the file ``credentials.json`` in the
        machines ``$HOME/.grid`` directory (if it exists).

        If no credentials have been stored, then you must pass in your API key and either
        your username or user id (if you know it). Your user id and API key can be found
        by navigating to *** INSERT INSTRUCTIONS TO FIND KEY HERE ***.

        Parameters
        ----------
        username
            your grid username. This is either be your github username or email address,
            depending on what you use when signing into the grid platform at:
            https://platform.grid.ai

        user_id
            Your grid user id. This can be found by ** INSERT INSTRUCTIONS HERE **
        api_key
            Your grid API key. This can be found by ** INSERT INSTRUCTIONS HERE **
        """

    def list_runs() -> List[str]:
        """Find the name of every run which you have access to.

        Returns
        -------
        List[str]
            all run names.
        """


    def cancel_run(name: str) -> List[str]:
        """Cancel all PENDING or RUNNING experiments within a run

        Parameters
        ----------
        name
            name of the run to cancel.

        Returns
        -------
        List[str]
            name of the experiments which have either been cancelled in the
            run or which which have previously reached a terminal state:
            "SUCCEEDED", "FAILED", or "CANCELLED".
        """


    def get_experiment_by_name(name: str) -> Experiment:
        """Retrive an experiment object by providing it's name.

        Parameters
        ----------
        name
            the name of the experiment you want to retrive.

            If you are part of a GridAI Teams account, you can retrieve
            one of your teammates experiments by providing the name in
            the following format: ``username:experiment_name``

        Returns
        -------
        Experiment
            an object whose properties and methods allow you natively ask Grid
            to retrieve up to date information, artifacts metrics, logs, and
            statuses, as well as perform certain administrative operations such
            as canceling a running experiment.
        """

    def get_experiment_by_id(exp_id: str) -> Experiment:
        """Retrive an experiment object by providing it's unique id.

        The id of an experiment is generated by Grid when the experiment is created.
        It can be found throughout the Experiment and Run objects by querying an
        experiment objects ``.id`` property.

        Parameters
        ----------
        exp_id
            the id of the experiment you want to retrive.

            If you are part of a GridAI Teams account, no change is needed in
            the formatting of the input to retrieve one of your teammates
            experiments. Just passing the id will perform a unique lookup for
            you.

        Returns
        -------
        Experiment
            an object whose properties and methods allow you natively ask Grid
            to retrieve up to date information, artifacts metrics, logs, and
            statuses, as well as perform certain administrative operations such
            as canceling a running experiment.
        """


    def get_build_logs(run_name: Optional[str] = None, exp_name: Optional[str] = None) -> Iterable[str]:
        """Output a run or experiment's build logs.

        If the build is currently executing, looping over the iterator will yield
        logs lines for as long as the build continues. If the build is finished,
        then all log lines are available to be iterated over immediatly and no
        wait period is required.

        Parameters
        ----------
        run_name
            name of a run to retrieve the build logs for.
        exp_name
            name of an experiment to retrieve the build logs for.

        Yields
        -------
        Iterable[str]
            Iterator where each element is a single line of the build log output.
            The first element return is the first line in the build log.
        """

    def get_experiment_logs(name: str) -> List[str]:
        """
        If the experiment is currently executing, looping over the iterator
        will yield logs lines for as long as the experiment continues. If
        the experiment is finished, then all log lines are available to be
        iterated over immediatly and no wait period is required.

        Parameters
        ----------
        name
            name of an experiment to retrieve the logs for.

        Yields
        -------
        Iterable[str]
            Iterator where each element is a single line of the experiment
            stdout log output. The first element return is the first line
            in the build log.
        """


    def cancel_experiment(name: str) -> str:
        """Cancel a PENDING or RUNNING experiment.

        Parameters
        ----------
        name
            name of the experiment to cancel.

        Returns
        -------
        str
            name of the experiment which has been cancelled.
        """


## Run Object

Import this via: ``from grid import Run``

    class Run:

        def __init__(
            self,
            name: str = '',
            entrypoint: Union[str, Path] = '',
            script_args: str = '',
            description: str = None,
            strategy: str = 'grid_search',
            num_trials: int = 0,  # if strategy == random
            framework: str = 'lightning',
            dependency_file: Union[str, Path] = '',
            instance_type: str = 't2.medium',
            use_spot: bool = False,
            cpus: int = 0,  # if < 1 use max on instance
            gpus: int = 0,  # if < 1 and gpus are on machine, use max on machine
            memory: str = '',
            datastore_name: str = '',
            datastore_version: str = '',
            datastore_mount_dir: str = '',
            scratch_size: str = '',
            scratch_mount_path: str = '/tmp/scratch',
            localdir: bool = False,
            dockerfile: Union[str, Path] = '',
            config_file: Union[str, Path] = '',
            cluster: str = '',
            run_id: str = '',  # TODO(rlizzo): don't alias python reserved name
        ):
            """A ``Run`` is a container for a set of computations executed over search space.

            This object can be instantiated with constructor args below in
            order to create/start a new set of computations (``Experiments``)
            which make up the ``Run``.

            Alternatively, an existig ``Run`` ``name`` can be passed in the
            constructor, and the SDK will load all the associated ``Run`` /
            ``Experiment`` details in this structure automatically.

            This class provides properties for access to run attributes
            which can be read at any time, or set before the ``Run``
            objects ``.start()`` method is called.

            Parameters
            ----------
            name
                name of the run. If loading a ``Run`` that already exists,
                this must be provided. If creating a new ``Run`` then setting
                this field is optional (a unique name will be assigned for you).
            entrypoint
                Path to the script which should actually be run.
            script_args
                The hyperparameter search arguments which are being used to
                run the ``entrypoint`` stript.
            description
                Optional human readable description of the ``Run``
            strategy
                one of ``"grid_search"`` or ``"random_search"``. Grid search executes
                all combinations of parameters in the search space, random search
                executes ``num_trials`` selected at random from the search space.
                Note: the ``num_trials`` argument must be set if using the
                ``"random_search"`` strategy.
            num_trials
                when using ``"random_search" strategy``, the number of experiments
                to execute within the possible search space.
            framework
                The machine learning framework to load. Must be one of ``["lightning",
                "pytorch", "tensorflow", "julia"]``. By default, ``"lightning"``
            dependency_file
                Path to a dependency file to use to install runtime requirements.
            instance_type
                name of the compute instance type to use when launching the instance
                computations
            use_spot
                If ``True``, inturuptable instance types will be used to launch the
                experiment computations. This trades the potential of longer
                times to completion for drastically reduced prices.
            cpus
                The number of CPUs to assign to each experiment. Grid reserves one
                CPU core on each node to run our managment layer, so this value
                must be ``<= num_cpus_per_node - 1``
            gpus
                The number of GPUs to assign to each experiment on a node. To optimize
                costs ensure the following is True: ``num_gpus_per_node % gpus = 0``
            memory
                DEPRECATED. Do not use
            datastore_name
                If attaching a datastore to the running experiments, the name of
                the datastore you wish to use.
            datastore_version
                If attaching a datastore to the running experiments, the version
                of the datastore which should be used.
            datastore_mount_dir
                If attaching a datastore to the running experiments, the file
                path where the datastore root path is located.
            scratch_size
                DEPRECATED. Do not use
            scratch_mount_path
                DEPRECATED. Do not use
            localdir
                if True, A non-github compatible source code directory is being
                used to execute this experiment.
            dockerfile
                If passed a path to a Dockerfile in the repository, use this
                Dockerfile to actually launch the experiments.
            config_file
                An optional path to a configuration file in the repo which can
                statically store most of the inputs provided in these arguments.
            cluster
                For bring your own cluster users, the name of the cluster which
                you would like to use to run this experiment
            run_id
                INTERNAL ONLY. Do not use.
            """

### Run Object Properties

    @property
    def name(self) -> str:
        """Name of the Run
        """

    @property
    def entrypoint(self) -> Union[str, Path]:
        """Path to the script which should actually be run.
        """

    @property
    def script_args(self) -> str:
        """Set of entrypoint script arguments which set up the search space to compute over.
        """

    @property
    def description(self) -> str:
        """Human readable description of the Run's contents
        """

    @property
    def strategy(self) -> str:
        """Hyperparameter search strategy. Must be one of ``['grid_search', 'random_search']``
        """

    @property
    def num_trials(self) -> int:
        """How many samples of full search space are used using the ``'random_search'`` strategy.
         """

    @property
    def framework(self) -> str:
        """The ML framework used. One of ``["lightning", "pytorch", "tensorflow", "julia"]``.
        """

    @property
    def dependency_file(self) -> Union[str, Path]:
        """Path to a dependency file to use to install runtime requirements.
        """

    @property
    def instance_type(self) -> str:
        """name of the compute instance type to use when launching the instance computations.
        """

    @property
    def use_spot(self) -> bool:
        """If ``True``, inturuptable instance types will be used to launch the experiment computations.
        """

    @property
    def cpus(self) -> int:
        """The number of CPUs to assign to each experiment
        """

    @property
    def gpus(self) -> int:
        """The number of GPUs to assign to each experiment on a node
        """

    @property
    def memory(self) -> str:
        """DEPRECATED. Do not use
        """

    @property
    def datastore_name(self) -> str:
        """If attaching a datastore to the running experiments, the name of the datastore you wish to use.
        """

    @property
    def datastore_version(self) -> str:
        """If attaching a datastore to the running experiments, the version of the datastore which should be used.
        """

    @property
    def datastore_mount_dir(self) -> str:
        """If attaching a datastore to the running experiments, the file path where the datastore root path is located.
        """

    @property
    def scratch_size(self) -> str:
        """DEPRECATED. Do not use
        """

    @property
    def scratch_mount_path(self) -> str:
        """DEPRECATED. Do not use
        """

    @property
    def localdir(self) -> bool:
        """if True, A non-github compatible source code directory is being used to execute this experiment.
        """
    
    @property
    def dockerfile(self) -> Union[str, Path]:
        """If passed a path to a Dockerfile in the repository, use this Dockerfile to actually launch the experiments.
        """
        
    @property
    def config_file(self) -> Union[str, Path]:
        """Path to a config file which can set most of the Run options.
        """

    @property
    def cluster(self) -> str:
        """Name of the cluster the computations execute on. 
        """
    
    @property
    def id(self) -> str:
        """Id of the run.
        """
        
    @property
    def experiments(self) -> Mapping[str, 'Experiment']:
        """A mapping view of experiment names -> experiment interaction objects.
        """

    @property
    def user(self) -> SDKUser:
        """An object containing details about the user who created this ``Run``
        """
    

    @property
    def grid_config(self) -> dict:
        """The grid config of the run (either auto generated or specified explicitly).

        Returns
        -------
        dict
            nested dictionary corresponding to the grid YAML nesting structure

        See Also
        --------
        - Grid yaml config specification:
          https://docs.grid.ai/products/run-run-and-sweep-github-files/yaml-configs/yaml-api
        """

    @property
    def estimated_hourly_cost(self) -> Union[int, float]:
        """Estimated hourly cost of the run.

        Returns
        -------
        Union[int, float]
            Value corresponding to (estimated) cost / hr in US Dollars.
        """
        
    @property
    def script_command(self) -> str:
        """Set of entrypoint script arguments which set up the search space to compute over.
        """

    @property
    def created_at(self) -> datetime:
        """Datetime inidicating the timestamp at which the experiments in a Run were submitted for execute.
        """

### Run Object Methods

    def start(self):
        """Start performing the computations described by the configuration of this ``Run`` object.
        """
        
    def __repr__(self) -> str:
        """Print out a human readable summary of the Run contents
        """

    def __contains__(self, item: str) -> bool:
        """Check if an experiment with the provided name exists in the Run.

        Returns
        -------
        bool
            True if the experiment exists, otherwise False.
        """

    def __len__(self) -> int:
        """Check how many experiments are recorded in the Run.

        Returns
        -------
        int
            Number of experiments recorded in the Run.
        """

    def __iter__(self) -> Iterable['Experiment']:
        """Allows for iteration over the run, yielding every Experiment object recorded.
        """

    def status(self) -> Mapping[str, Collection[str]]:
        """Requests the status for all Experiments in the run from the grid platform.

        Returns
        -------
        Mapping[str, Collection[str]]
            Mapping of statuses ("QUEUED", "RUNNING", "FAILED", "CANCELLED",
            "COMPLETED") to collection of experiment names which are in
            that particular state.
        """

    def cancel(self) -> List[str]:
        """Requests the grid platform cancels every Experiment in the Run.

        Returns
        -------
        List[str]
            a collection of experiment names if each experiment was successfully
            cancelled or had previously reached a terminal status ("CANCELLED",
            "FAILED", "COMPLETED").
        """

    def build_logs(self, n_lines: int = 200) -> Iterable[str]:
        """Request the build logs for this experiment from the grid platform.

        Parameters
        ----------
        n_lines
            Max number of lines to return. By default, 200.

        Yields
        -------
        str
            every return is a single line of the build log output;
            sorted by order of time, oldest log is at index 0,
            latest log is at the end of the list.
        """


## Experiment Objects

An experiment object is a singular instatiation of on point in 
the entire hyperparameter search space. This object is created after
a run begins and can be used to access more granular info about 
the computations occuring in the run.

### Experiment Object Properties

    @property
    def id(self) -> str:
        """Id of the experiment
        """

    @property
    def name(self) -> str:
        """The name of this experiment. Typically ``run-name + -expN``.
        """

    @property
    def created_at(self) -> datetime:
        """Datetime which the experiment was first scheduled to start.
        """

    @property
    def started_running_at(self) -> datetime:
        """Datetime when the experiment actually started running.
        """

    @property
    def finished_at(self) -> datetime:
        """Datetime when the experiment finished running (either completed, failed, or cancelled).
        """

    @property
    def invocation_commands(self) -> str:
        """Command which was used to kick off the script's job.
        """

    @property
    def parameters(self) -> dict:
        """Dict of hyperparameter names/values which this experiment used
        """

    @property
    def user(self) -> User:
        """User who launched this experiment.
        """

    @property
    def github_id(self) -> str:
        """Github project which the code in this experiment runs from.
        """

    @property
    def commit_sha(self) -> str:
        """Commit sha which of a git repo which the code runs from.
        """

### Experiment Object Methods

    def status(self) -> str:
        """Queries the grid platform to retrieve the current state of this experiment.

        Returns
        -------
        str
            one of "QUEUED", "RUNNING", "CANCELLED", "FAILED", "COMPLETED"
        """

    def cancel(self) -> str:
        """Request the grid platform cancels the experiment

        Returns
        -------
        str
            Name of the experiment if it was successfully cancelled or had
            previously reached a terminal status ("CANCELLED", "FAILED", "COMPLETED").
        """

    def build_logs(self, n_lines: int = 200) -> Iterable[str]:
        """Request the build logs for this experiment from the grid platform.

        Parameters
        ----------
        n_lines
            Max number of lines to return. By default, 200.

        Yields
        -------
        str
            every return is a single line of the build log output;
            sorted by order of time, oldest log is at index 0,
            latest log is at the end of the list.
        """

    def logs(self, n_lines: int = 200) -> Iterable[str]:
        """Request the stdout logs for this experiment from the grid platform.

        Parameters
        ----------
        n_lines
            Max number of lines to return. By default, 200.

        Yields
        -------
        str
            every return is a single line of the build log output;
            sorted by order of time, oldest log is at index 0,
            latest log is at the end of the list.
        """


## Intro Tutorial

```python
from pathlib import Path

from grid import login, Run

login(username='rlizzo', api_key='b766f422-6e64-434b-b643-5be3258634b6')

r = Run(
    entrypoint='./Demo_Project/run.py',
    script_args='--max_epochs "[10, 20]" --learning_rate "uniform(1e-3, 1e-5, 1)"',
    instance_type='t2.xlarge',
    cpus=3,
)

r
```

    Run(
        name=,
        description="None",
        script_command=,
        num_experiments=0,
        status={},
        user=rlizzo,
        created_at=None,
        cluster=,
    )

```python
r.estimated_hourly_cost
```

    0.38

```python
r.start()
```

    /Users/rick/projects/grid/grid-cli/grid/sdk/source_code/dependency_manager.py:212: UserWarning: Your requirements.txt or environment.yml are missing the following packages:
     torch 
    Your experiment could crash if these are missing! Add them yourself or try `grid sync-env`
      warnings.warn(message)

```python
r
```

    Run(
        name=peculiar-shockley-4136,
        description="None",
        script_command=./Demo_Project/run.py --script_args '"'"'--max_epochs "[10, 20]" --learning_rate "uniform(1e-3, 1e-5, 1)"'"'"' --instance_type t2.xlarge --cpus 3 ./Demo_Project/run.py --max_epochs '"'"'[10, 20]'"'"' --learning_rate '"'"'uniform(1e-3, 1e-5, 1)'"'"'',
        num_experiments=2,
        status={'QUEUED': 2},
        user=rlizzo,
        created_at=2021-08-10 16:59:58.044624+00:00,
        cluster=grid-cloud-prod,
    )

```python
r.status()
```

    defaultdict(list,
                {'QUEUED': ['peculiar-shockley-4136-exp0',
                  'peculiar-shockley-4136-exp1']})

```python
r.created_at
```

    datetime.datetime(2021, 8, 10, 16, 59, 58, 44624, tzinfo=datetime.timezone.utc)

```python
r.name
```

    'peculiar-shockley-4136'

```python
r.experiments
```

    {'peculiar-shockley-4136-exp0': Experiment(, 
         name=peculiar-shockley-4136-exp0, 
         status=QUEUED, 
         project=gridai/Demo_Project @ 570cd62aa05579e599609f3178344d5d208799dd, 
         parameters={'Script': 'run.py', 'max_epochs': '10', 'learning_rate': '0.0007056001691752508'}, 
         invocation_command=python run.py --max_epochs 10 --learning_rate 0.0007056001691752508, 
         user=rlizzo, 
         created_at=2021-08-10 16:59:58.058882, 
         started_running_at=1970-01-01 00:00:00, 
         finished_at=1970-01-01 00:00:00, 
     ),
     'peculiar-shockley-4136-exp1': Experiment(, 
         name=peculiar-shockley-4136-exp1, 
         status=QUEUED, 
         project=gridai/Demo_Project @ 570cd62aa05579e599609f3178344d5d208799dd, 
         parameters={'Script': 'run.py', 'max_epochs': '20', 'learning_rate': '0.0007056001691752508'}, 
         invocation_command=python run.py --max_epochs 20 --learning_rate 0.0007056001691752508, 
         user=rlizzo, 
         created_at=2021-08-10 16:59:58.063336, 
         started_running_at=1970-01-01 00:00:00, 
         finished_at=1970-01-01 00:00:00, 
     )}

```python
r.experiments['peculiar-shockley-4136-exp0']
```

    Experiment(, 
        name=peculiar-shockley-4136-exp0, 
        status=PENDING, 
        project=gridai/Demo_Project @ 570cd62aa05579e599609f3178344d5d208799dd, 
        parameters={'Script': 'run.py', 'max_epochs': '10', 'learning_rate': '0.0007056001691752508'}, 
        invocation_command=python run.py --max_epochs 10 --learning_rate 0.0007056001691752508, 
        user=rlizzo, 
        created_at=2021-08-10 16:59:58.058882, 
        started_running_at=1970-01-01 00:00:00, 
        finished_at=1970-01-01 00:00:00, 
    )


```python
r.experiments['peculiar-shockley-4136-exp0'].cancel()
```

    'peculiar-shockley-4136-exp0'


```python
r.status()
```

    defaultdict(list,
                {'CANCELLED': ['peculiar-shockley-4136-exp0'],
                 'PENDING': ['peculiar-shockley-4136-exp1']})




```python
from grid import list_runs

list_runs()
```

    ['peculiar-shockley-4136',
     'nice-nightingale-152-cl8102124654',
     'nice-nightingale-152',
     'clever-bouman-4749',
     'striped-hamilton-1458',
     'classy-mandrill-288',
     'tactful-burnell-7171',
     'brainy-gopher-730-cl7921101940']


```python
rr = Run('striped-hamilton-1458')

rr
```

    Run(
        name=striped-hamilton-1458,
        description="None",
        script_command=Demo_Project/run.py --script_args '"'"'--max_epochs "[10, 20]" --learning_rate "uniform(1e-3, 1e-5, 1)"'"'"' --instance_type t2.xlarge --cpus 3 Demo_Project/run.py --max_epochs '"'"'[10, 20]'"'"' --learning_rate '"'"'uniform(1e-3, 1e-5, 1)'"'"'',
        num_experiments=2,
        status={'SUCCEEDED': 2},
        user=rlizzo,
        created_at=2021-08-10 04:20:27.619203+00:00,
        cluster=,
    )